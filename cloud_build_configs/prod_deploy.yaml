# Cloud build configuration to build a docker training image, submit it to the image registry, and run a training job
# https://cloud.google.com/build/docs/building/build-containers
# https://cloud.google.com/build/docs/configuring-builds/substitute-variable-values 
# https://cloud.google.com/build/docs/build-config-file-schema

substitutions:
  _IMAGE_NAME: "github.com/bieniekalexander/ml-model-promotion"
  _TAG_NAME: "${COMMIT_SHA}"
  _REGION: us-east1
  _GCS_MODEL_DIRECTORY: "gs://mw-ds-model-promotion-poc-qa/census_model"
  _MODEL_NAME: "census_model_${_TAG_NAME}"
  _ENDPOINT_NAME: "census_model_endpoint"
timeout: 1800s

steps:
- id: "Write a python util to parse gcloud data"
  name: "gcr.io/cloud-builders/curl"
  entrypoint: /bin/bash
  args:
    - -c
    - |
      # this python util is helping me make up for the lack of jq on gcloud build images:
      # jq '.[] | select(.displayName=="${_MODEL_NAME}") | .name'
      # | sed 's/"//g' \
      # | awk -F'/' '{  print $6 }'
      cat <<EOF > /workspace/get_id_by_display_name.py
      from __future__ import print_function
      import argparse
      import json

      def get_id_by_display_name(lst, display_name):
        """ Find the json object with the specified display name, and return the id field at the end of the object's name """
        items = list(filter(lambda x: x['displayName']==display_name, lst))

        if items:
          item = items[0]
          return item['name'].rsplit('/', 1)[-1]
        else:
          return ""


      if __name__ == "__main__":
        parser = argparse.ArgumentParser(description='Get id of google api object from display name')
        parser.add_argument('--display-name', dest='display_name', required=True,
                          help='name of google object to find')
        parser.add_argument('--json-path', dest='json_path', required=True,
                          help='path to the json file to read')

        args = parser.parse_args()
        obj = json.load(open(args.json_path, 'r'))

        assert isinstance(obj, list)

        print(get_id_by_display_name(obj, args.display_name), end='')
      EOF

# https://cloud.google.com/sdk/gcloud/reference/ai/models
# TODO a model should be able to receive new versions, but it looks like vertex AI doesn't allow this through the CLI yet
# TODO how are we selecting the right container to build from? It's hardcoded right now
- id: "Upload/Update a Vertex AI Model using the serialized model we just uploaded"
  name: gcr.io/cloud-builders/gcloud
  entrypoint: /bin/bash
  args:
    - -c 
    - |
      # check if the model currently exists, as identified by display name
      # TODO what if display name isn't unique? Is there a better identifier?
      gcloud ai models list --region=${_REGION} --format=json > /workspace/gcloud_response.json
      python /workspace/get_id_by_display_name.py --display-name=${_MODEL_NAME} --json-path=/workspace/gcloud_response.json > /workspace/model_id
      rm /workspace/gcloud_response.json

      if [ -s /workspace/model_id ]; then
        echo "Model Uploaded model $(</workspace/model_id) exists, TODO update model"
        # gcloud ai models update ... # TODO update when model update command exists
        exit 2
        echo "Updated model $(</workspace/model_id)"
      else
        echo "Model does not exist, uploading new model"
        gcloud ai models upload \
        --container-image-uri=us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest \
        --artifact-uri=$_GCS_MODEL_DIRECTORY \
        --display-name=${_MODEL_NAME} \
        --region=$_REGION

        gcloud ai models list --region=${_REGION} --format=json > /workspace/gcloud_response.json
        python /workspace/get_id_by_display_name.py --display-name=${_MODEL_NAME} --json-path=/workspace/gcloud_response.json > /workspace/model_id
        rm /workspace/gcloud_response.json

        echo "Uploaded model $(</workspace/model_id)"
      fi


# https://cloud.google.com/sdk/gcloud/reference/ai/endpoints
# https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api
- id: "Create/Update a Vertex AI Endpoint and deploy the new model to it"
  name: gcr.io/cloud-builders/gcloud
  entrypoint: /bin/bash
  args:
    - -c 
    - |
      # check if the endpoint currently exists, as identified by display name
      # TODO what if endpoint name isn't unique? Is there a better identifier?
      gcloud ai endpoints list --region=${_REGION} --format=json > /workspace/gcloud_response.json
      python /workspace/get_id_by_display_name.py --display-name=${_ENDPOINT_NAME} --json-path=/workspace/gcloud_response.json > /workspace/endpoint_id
      rm /workspace/gcloud_response.json

      if [ -s /workspace/endpoint_id ]; then
        echo "Endpoint $(</workspace/endpoint_id) exists, skipping endpoint creation"
      else
        echo "Endpoint does not exist yet, creating endpoint"
        gcloud ai endpoints create \
          --display-name=${_ENDPOINT_NAME} \
          --region=${_REGION}

        gcloud ai endpoints list --region=${_REGION} --format=json > /workspace/gcloud_response.json
        python /workspace/get_id_by_display_name.py --display-name=${_ENDPOINT_NAME} --json-path=/workspace/gcloud_response.json > /workspace/endpoint_id
        rm /workspace/gcloud_response.json
        echo "Created endpoint $(</workspace/endpoint_id)"
      fi

      gcloud ai endpoints deploy-model $(</workspace/endpoint_id) \
        --project=${PROJECT_ID} \
        --region=${_REGION} \
        --display-name=${_MODEL_NAME} \
        --model=$(</workspace/model_id) \
        --traffic-split=0=100
      
      echo "Deployed model $(</workspace/model_id) to endpoint $(</workspace/endpoint_id)"
